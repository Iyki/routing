{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26dac936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import generator\n",
    "import model\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb7e081",
   "metadata": {},
   "source": [
    "### Loss functions and Embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b425211f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/lib/python3/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import fastbook\n",
    "from fastbook import *\n",
    "from fastai.collab import *\n",
    "from fastai.tabular.all import *\n",
    "from fastai.losses import *\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def get_small_emb_sz(dls_df, n_bits=None):\n",
    "    emb = get_emb_sz(dls_df)   # corresponds to number of nodes in each column\n",
    "    print(\"recommended emb size\", emb)\n",
    "    emb = max(emb,key=lambda x:x[0])\n",
    "    if n_bits == None:\n",
    "        n_bits = embs[1]\n",
    "    print(\"\\tusing emb size:\", (emb[0], n_bits))\n",
    "    return [(emb[0], n_bits)]\n",
    "\n",
    "\n",
    "def MRELoss(inp, targ) -> Tensor:\n",
    "    inp = torch.flatten(inp).float()\n",
    "    targ = torch.flatten(targ).float()\n",
    "    nom = torch.nn.functional.l1_loss(inp, targ)\n",
    "    noo = torch.Tensor([0]).repeat(targ.size(0)).to(device)\n",
    "    denom = torch.nn.functional.l1_loss(noo, targ)\n",
    "    loss = (nom / denom).mean()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def CombineLoss(inp, targ) -> Tensor:\n",
    "    mse_loss = MSELossFlat()\n",
    "    loss_1 = mse_loss(inp, targ)\n",
    "\n",
    "    loss_2 = MRELoss(inp, targ)\n",
    "\n",
    "    return alpha * loss_1 + (1 - alpha) * loss_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce5d92bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.recorder()from fastai2.imports import *\n",
    "# from fastai2.torch_core import *\n",
    "# from fastai2.learner import *\n",
    "# call as: learn.recorder.plot_metrics()\n",
    "@patch\n",
    "@delegates(subplots)\n",
    "def plot_metrics(self: Recorder, nrows=None, ncols=None, figsize=None, **kwargs):\n",
    "    metrics = np.stack(self.values)\n",
    "    names = self.metric_names[1:-1]\n",
    "    n = len(names) - 1\n",
    "    if nrows is None and ncols is None:\n",
    "        nrows = int(math.sqrt(n))\n",
    "        ncols = int(np.ceil(n / nrows))\n",
    "    elif nrows is None: nrows = int(np.ceil(n / ncols))\n",
    "    elif ncols is None: ncols = int(np.ceil(n / nrows))\n",
    "    figsize = figsize or (ncols * 6, nrows * 4)\n",
    "    fig, axs = subplots(nrows, ncols, figsize=figsize, **kwargs)\n",
    "    axs = [ax if i < n else ax.set_axis_off() for i, ax in enumerate(axs.flatten())][:n]\n",
    "    for i, (name, ax) in enumerate(zip(names, [axs[0]] + axs)):\n",
    "        ax.plot(metrics[:, i], color='#1f77b4' if i == 0 else '#ff7f0e', label='valid' if i > 0 else 'train')\n",
    "        ax.set_title(name if i > 1 else 'losses')\n",
    "        ax.legend(loc='best')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13cf1cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(dataset, loss_function, n_bits, valid_pct, savepath):\n",
    "    if (not os.path.exists(savepath)):\n",
    "        os.makedirs(savepath)\n",
    "\n",
    "    data = np.array(dataset)\n",
    "    df = pd.DataFrame(data, columns=['src', 'dst', 'label'])\n",
    "    dls_df = CollabDataLoaders.from_df(df, bs=64, valid_pct=valid_pct)\n",
    "    \n",
    "    embs_sz = get_small_emb_sz(dls_df, n_bits)\n",
    "    # multiply number of nodes by 2. max distance cannot be larger than this\n",
    "    # this represents the max width of an individual graph\n",
    "    max_value = df.label.max() * 2\n",
    "    print(\"max value is\", max_value, \"gotten by max label:\", df.label.max(), \"* embedding matrix size: \", embs_sz[0][0])\n",
    "    trainer = model.CollabNN(*embs_sz, y_range=(0, max_value))\n",
    "\n",
    "    learn = Learner(dls_df, trainer, loss_func=loss_function, path=savepath, metrics=[mse, mae, MRELoss])\n",
    "    \n",
    "    return learn, df\n",
    "\n",
    "def train_model(dataset, num_epochs, loss_function, n_bits=None, valid_pct=0.2, savepath=\"save/default/\"):\n",
    "\n",
    "    learn, df = create_model(dataset, loss_function, n_bits, valid_pct, savepath)\n",
    "\n",
    "#     SaveModelCallback(with_opt=True)\n",
    "#     learn.remove_cb(ProgressCallback) #remove (uncomment) progresscallback if running from terminal\n",
    "\n",
    "    learn.fit_one_cycle(n_epoch=num_epochs, lr_max=5e-3, wd=0.01) \n",
    "                        #cbs=[EarlyStoppingCallback(monitor='train_loss', min_delta=0.001, patience=50)])  #ShowGraphCallback(), \n",
    "    \n",
    "    allnodes = set(df.src).union(set(df.dst))\n",
    "    embs = learn.model.save_embeddings(Tensor(list(allnodes)).to(device).int())\n",
    "\n",
    "    with open(savepath + \"embeddings.pkl\", \"wb\") as outfile:\n",
    "        pickle.dump(embs, outfile)\n",
    "    \n",
    "    learn.export()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d714327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shared hyperparams\n",
    "num_epochs = 300\n",
    "alpha = 0.5\n",
    "loss_function = CombineLoss\n",
    "n_bits = 4\n",
    "lg_N = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "valid_pct = 0.2\n",
    "\n",
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f644b33",
   "metadata": {},
   "source": [
    "### get the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d586db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cycles_dataset(lg_N, train_pct=0.8):\n",
    "    cy_datapath =  'save/cycle/data/log_' + str(lg_N) + '_data'\n",
    "\n",
    "    if os.path.isfile(cy_datapath):\n",
    "        cycles_dataset = generator.load_dataset_from_file(cy_datapath)\n",
    "    else:\n",
    "        cycles_dataset = generator.generate_cycles_dataset(lg_N)\n",
    "        generator.save_dataset_to_file(cycles_dataset, cy_datapath)\n",
    "    cycles_dataset = np.array(cycles_dataset)\n",
    "    np.random.shuffle(cycles_dataset)\n",
    "    cycles_trainset, cycles_testset = cycles_dataset[:int(train_pct*len(cycles_dataset)),:], cycles_dataset[int(train_pct*len(cycles_dataset)):,:]\n",
    "    \n",
    "    return cycles_trainset, cycles_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a2e4f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graphs_dataset(train_pct=0.8, real_graph_paths=None):\n",
    "    if real_graph_paths == None:\n",
    "        real_graph_paths = [\n",
    "                            \"/jumbo/lisp/ike/code/DistanceLabelling/datasets/ENZYMES_g1/ENZYMES_g1.edges\",\n",
    "                            \"/jumbo/lisp/ike/code/DistanceLabelling/datasets/ENZYMES_g1/ENZYMES_g1.edges\", \n",
    "                           \"/jumbo/lisp/ike/code/DistanceLabelling/datasets/ENZYMES_g118/ENZYMES_g118.edges\"\n",
    "                           ]\n",
    "    gr_datapath =  'save/graph/data/ngraphs_' + str(len(real_graph_paths)) + '_data'\n",
    "\n",
    "    if os.path.isfile(gr_datapath):\n",
    "        graphs_dataset = generator.load_dataset_from_file(gr_datapath)\n",
    "    else:\n",
    "        graphs_dataset = generator.generate_real_graphs_dataset(real_graph_paths)\n",
    "        generator.save_dataset_to_file(graphs_dataset, gr_datapath)\n",
    "    graphs_dataset = np.array(graphs_dataset)\n",
    "    np.random.shuffle(graphs_dataset)\n",
    "    graphs_trainset, graphs_testset = graphs_dataset[:int(train_pct*len(graphs_dataset)),:], graphs_dataset[int(train_pct*len(graphs_dataset)):,:]\n",
    "    \n",
    "    return graphs_trainset, graphs_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "834bef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trees_dataset(lg_N, train_pct=0.8):\n",
    "    tr_datapath =  'save/tree/data/log_' + str(lg_N) + '_data'\n",
    "\n",
    "    if os.path.isfile(tr_datapath):\n",
    "        trees_dataset = generator.load_dataset_from_file(tr_datapath)\n",
    "    else:\n",
    "        trees_dataset = generator.generate_trees_dataset(2**lg_N)\n",
    "        generator.save_dataset_to_file(trees_dataset, tr_datapath)\n",
    "\n",
    "    trees_dataset = np.array(trees_dataset)\n",
    "    np.random.shuffle(trees_dataset)\n",
    "    trees_trainset, trees_testset = trees_dataset[:int(train_pct*len(trees_dataset)),:], trees_dataset[int(train_pct*len(trees_dataset)):,:]\n",
    "\n",
    "    return trees_trainset, trees_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "025d688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cycle_model(alpha, num_epochs, n_bits, loss_function, lg_N, train_pct):\n",
    "    # create and train on cycles\n",
    "    split = train_pct*100\n",
    "    cy_savepath = 'save/cycle/split_' +str(split)+ '/' +str(alpha)+ '_' + str(lg_N) + '_' + str(num_epochs) + '_'+str(n_bits)+ '/'\n",
    "\n",
    "    saved = cy_savepath+\"export.pkl\" \n",
    "    if os.path.isfile(saved):\n",
    "        cycle_model = load_learner(saved, cpu=False)  # learn.load('model')\n",
    "        print(\"exact model trained before... retrieved model\")\n",
    "    else:\n",
    "        cycles_dataset = get_cycles_dataset(lg_N)\n",
    "        cycle_model = train_model(cycles_dataset, num_epochs, loss_function, n_bits=n_bits, savepath=cy_savepath)\n",
    "        cycle_model.recorder.plot_metrics()\n",
    "    return cycle_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66944a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree_model(alpha, num_epochs, n_bits, loss_function, lg_N, train_pct):\n",
    "    # create and train on trees\n",
    "    split = train_pct*100\n",
    "    tr_savepath = 'save/tree/split_' + str(split) + '/' +str(alpha)+ '_' +str(lg_N)+ '_' +str(num_epochs)+ '_'+str(n_bits)+ '/'\n",
    "    saved = tr_savepath+\"export.pkl\"  # \"models/model.pth\"\n",
    "    if os.path.isfile(saved):\n",
    "        tree_model = load_learner(saved, cpu=False)  # learn.load('model')\n",
    "        print(\"exact model trained before... retrieved model\")\n",
    "    else:\n",
    "        trees_dataset = get_trees_dataset(lg_N, train_pct)\n",
    "        tree_model = train_model(trees_dataset, num_epochs, loss_function, n_bits=n_bits, savepath=tr_savepath)\n",
    "        print(tree_model.model.node_to_emb)\n",
    "        tree_model.recorder.plot_metrics()\n",
    "        \n",
    "    return tree_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccf22061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_model(alpha, num_epochs, n_bits, loss_function, train_pct):\n",
    "    split = train_pct*100\n",
    "    # create and train on real graphs\n",
    "    gr_savepath = 'save/graph/split_' + str(split) + '/' + str(alpha) + '_' + str(num_epochs) + '/'\n",
    "    saved = gr_savepath+\"export.pkl\"  # \"models/model.pth\"\n",
    "    if os.path.isfile(saved):\n",
    "        graph_model = load_learner(saved, cpu=False)  # learn.load('model')\n",
    "        print(\"exact model trained before... retrieved model\")\n",
    "    else:\n",
    "        graphs_dataset = get_graphs_dataset(train_pct)\n",
    "        graph_model = train_model(graphs_dataset, num_epochs, loss_function, n_bits=n_bits, savepath=gr_savepath)\n",
    "        graph_model.recorder.plot_metrics()\n",
    "    return graph_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f041b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5659b6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cycles_dataset[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80488996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cycle_model.model(Tensor([[0, 115]]).to(device).int()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0cb8285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cycle_model.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a67ff978",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trees_testset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# n = 10\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m testset \u001b[38;5;241m=\u001b[39m \u001b[43mtrees_testset\u001b[49m\n\u001b[1;32m      3\u001b[0m tst_data, y_targ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mIntTensor(testset[:,:\u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device), Tensor(np\u001b[38;5;241m.\u001b[39marray(testset)[:,\u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mint()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# display(data)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# tst = graph_model.embedding_layers(data[:, 0]), graph_model.embedding_layers(data[:, 1])\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# tst\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trees_testset' is not defined"
     ]
    }
   ],
   "source": [
    "# n = 10\n",
    "testset = trees_testset\n",
    "tst_data, y_targ = torch.IntTensor(testset[:,:2]).to(device), Tensor(np.array(testset)[:,2]).to(device).int()\n",
    "\n",
    "# display(data)\n",
    "# tst = graph_model.embedding_layers(data[:, 0]), graph_model.embedding_layers(data[:, 1])\n",
    "# tst\n",
    "\n",
    "\n",
    "preds = tree_model.model(data)\n",
    "\n",
    "calc_loss = MSELossFlat()\n",
    "calc_loss(preds, y_targ)\n",
    "# calc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7531bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bits_to_loss(max_bits, lossfunc):\n",
    "    plt.plot(xpoints, ypoints)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709122df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177d8d59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
