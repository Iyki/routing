{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26dac936",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_random_tree(n):\n",
    "  parent = {}\n",
    "  nodes = list(range(n))\n",
    "  random.shuffle(nodes)\n",
    "  root = nodes[0]\n",
    "  parent[root] = root\n",
    "  for i in range(1, len(nodes)):\n",
    "    parent[nodes[i]] = nodes[random.randrange(i)]\n",
    "  return parent\n",
    "\n",
    "import time\n",
    "def get_node_depths(tree):\n",
    "    depths = {}  # size of tree, node:level\n",
    "    #curr = root\n",
    "    for node in tree:\n",
    "        level = 0\n",
    "        curr = node\n",
    "        while tree[curr] != curr:\n",
    "            if curr in depths:\n",
    "                level += depths[curr]\n",
    "                break  \n",
    "            curr = tree[curr]\n",
    "            level += 1\n",
    "        depths[node] = level\n",
    "    return depths\n",
    "\n",
    "def get_distance(tree, src, dest, depths):\n",
    "    s = src; d = dest\n",
    "    while s != d:\n",
    "        if depths[d] > depths[s]:\n",
    "            d = tree[d]\n",
    "        elif depths[s] > depths[d]:\n",
    "            s = tree[s]\n",
    "        else:\n",
    "            if s != d and depths[s] == depths[d]:\n",
    "                d = tree[d]\n",
    "    lca = s\n",
    "    src_depth = depths[src] - depths[lca]\n",
    "    dest_depth = depths[dest] - depths[lca]\n",
    "    return (src_depth + dest_depth)\n",
    "\n",
    "# src, dst, distance_label\n",
    "#\n",
    "def generate_dataset(N):\n",
    "    dataset = []     # node1, node2, distance\n",
    "    node_id = {}\n",
    "    id_to_node = {}\n",
    "    node_pairs = {}  # (node1, node2): distance\n",
    "    \n",
    "    counter = 0\n",
    "    trees = {}\n",
    "    depths_graph = {}\n",
    "    # give each node a unique id\n",
    "    for n in range(3, N): # For each tree\n",
    "        trees[n] = generate_random_tree(n)\n",
    "        tree = trees[n]\n",
    "        depths_graph[n] = get_node_depths(tree)        \n",
    "        for node in tree: # For each node in the tree\n",
    "            node_id[(n, node)] = counter\n",
    "            id_to_node[counter] = n, node\n",
    "            counter += 1\n",
    "    \n",
    "    for n in range(3, N):\n",
    "        tree = trees[n]\n",
    "        depths = depths_graph[n]\n",
    "        for node in tree:\n",
    "            for other_node in tree:\n",
    "                dist = get_distance(tree, node, other_node, depths)\n",
    "                dataset.append([node_id[(n, node)], node_id[(n, other_node)], dist])\n",
    "                node_pairs[(node_id[(n, node)], node_id[(n, other_node)])] = dist\n",
    "                \n",
    "    return dataset, node_pairs, id_to_node, node_id\n",
    "# generate_dataset(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a267baf5",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.collab import *\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "class CollabNN(Module):\n",
    "    predictions = {}\n",
    "    embeddings = {}\n",
    "    def __init__(self, src_sz, y_range, n_act=200):\n",
    "        self.node_factors = Embedding(*src_sz)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(src_sz[1]+src_sz[1], n_act),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_act, 1))\n",
    "        self.y_range = y_range\n",
    "        self.prediction = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_copy = torch.clone(x)\n",
    "        embs = self.node_factors(x[:,0]), self.node_factors(x[:,1])\n",
    "        x = self.layers(torch.cat(embs, dim=1))\n",
    "        self.prediction = sigmoid_range(x, *self.y_range)\n",
    "\n",
    "        for i in range(len(x)):\n",
    "          pair = x_copy[i]\n",
    "          CollabNN.predictions[(int(pair[0]),int(pair[1]))] = float(self.prediction[i])\n",
    "          CollabNN.embeddings[int(pair[0])] = float(embs[0][i])\n",
    "          CollabNN.embeddings[int(pair[1])] = float(embs[1][i])\n",
    "        return self.prediction\n",
    "\n",
    "    def get_predictions(self):\n",
    "      return self.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b379c5f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import generator\n",
    "import model\n",
    "import pickle\n",
    "import torch\n",
    "from fastbook import *\n",
    "from fastai.collab import *\n",
    "from fastai.tabular.all import *\n",
    "from fastai.losses import *\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def get_small_emb_sz(dls_df):\n",
    "    emb = get_emb_sz(dls_df)\n",
    "    return [(emb[0][0], 1)]\n",
    "\n",
    "\n",
    "def MRELoss(inp, targ) -> Tensor:\n",
    "    inp = torch.flatten(inp).float()\n",
    "    targ = torch.flatten(targ).float()\n",
    "    nom = torch.nn.functional.l1_loss(inp, targ)\n",
    "    noo = torch.Tensor([0]).repeat(targ.size(0)).to(device)\n",
    "    denom = torch.nn.functional.l1_loss(noo, targ)\n",
    "    loss = (nom / denom).mean()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def CombineLoss(inp, targ) -> Tensor:\n",
    "    mse_loss = MSELossFlat()\n",
    "    loss_1 = mse_loss(inp, targ)\n",
    "\n",
    "    loss_2 = MRELoss(inp, targ)\n",
    "\n",
    "    return alpha * loss_1 + (1 - alpha) * loss_2\n",
    "\n",
    "\n",
    "lg_N = 10\n",
    "num_epochs = 1000\n",
    "alpha = 0.5\n",
    "loss_function = CombineLoss\n",
    "\n",
    "\n",
    "'''\n",
    "Data can either be generated from scratch or read from a file that it was previously saved to\n",
    "'''\n",
    "\n",
    "savepath = 'save/' + str(alpha) + '_' + str(lg_N) + '_' + str(num_epochs) + '/'\n",
    "\n",
    "dataset, node_pairs, id_to_node, node_id = generate_dataset(2**lg_N)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b21b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data = np.array(dataset)\n",
    "\n",
    "# if loading from csv, cut the first column out (line numbers)\n",
    "# df = pd.DataFrame(data[:, 1:], columns=['src', 'dst', 'label'])\n",
    "# node_pairs = pd.read_pickle(savepath + 'node_pairs.pkl')\n",
    "# node_id = pd.read_pickle(savepath + 'node_id.pkl')\n",
    "\n",
    "# otherwise (if generated), use data directly\n",
    "df = pd.DataFrame(data, columns = ['src','dst','label'])\n",
    "\n",
    "\n",
    "dls_df = CollabDataLoaders.from_df(df, bs=64)\n",
    "embs = get_small_emb_sz(dls_df)\n",
    "trainer = model.CollabNN(*embs, y_range=(0, embs[0][0]))\n",
    "# learn = Learner(dls_df, trainer, loss_func = loss_function, path=savepath)\n",
    "\n",
    "learn = Learner(dls_df, trainer, loss_func=loss_function, path=savepath, metrics=[mse, mae, MRELoss])\n",
    "\n",
    "# # torch.save(trainer, modelpath + 'model.pth')\n",
    "# learn.save('model')\n",
    "# with open(savepath + \"predictions.pkl\", \"wb\") as outfile:\n",
    "#     pickle.dump(model.CollabNN.predictions, outfile)\n",
    "# with open(savepath + \"embeddings.pkl\", \"wb\") as outfile:\n",
    "#     pickle.dump(model.CollabNN.embeddings, outfile)\n",
    "\n",
    "# learn.load('model')\n",
    "# SaveModelCallback(with_opt=True), \n",
    "learn.fit_one_cycle(n_epoch=num_epochs, lr_max=5e-3, wd=0.01, cbs=[ShowGraphCallback()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d92bf",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f041b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
